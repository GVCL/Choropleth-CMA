# -*- coding: utf-8 -*-
"""PaddleOCR_updated_complete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bim4lZC51znxumQwyGhN_j-aKS6y2lmN
"""

!pip install paddlepaddle
!pip install paddleocr

!git clone https://github.com/PaddlePaddle/PaddleOCR

from paddleocr import PaddleOCR, draw_ocr
from matplotlib import pyplot as plt
import cv2
import glob
from google.colab import drive
drive.mount('/content/drive')

# !unzip test_set_1.zip

ocr_model = PaddleOCR(lang='en')

img_path = '/content/drive/MyDrive/map_detect/annotation/final_test_set/2018'

img_paths = glob.glob(img_path + '*.png')

results = {}

import pandas as pd
annotations_df = pd.read_csv("/content/drive/MyDrive/map_detect/annotation/final_result/2018/final_2018.csv")

data=[]
for row in annotations_df.itertuples():
    file_name = row[1]
    map_type = row[4]
    title_bounding_box = row[3]
    legend_bounding_box = row[2]
    data.append((file_name, map_type, title_bounding_box, legend_bounding_box))

print(data)

data = [(file_name, map_type, title_bounding_box, legend_bounding_box.replace('(79,', '(84,')) for file_name, map_type, title_bounding_box, legend_bounding_box in data]
print(data)
# data = [(file_name, map_type, title_bounding_box, legend_bounding_box.replace('(80,', '(84,')) for file_name, map_type, title_bounding_box, legend_bounding_box in data]
# print(data)

def convert_to_doubles(low, upper_bound):
  low=lower_bound.replace(",", "")
  up=upper_bound.replace(",", "")
  print(low)
  print(up)
  if low and not low[-1].isdigit():
      units = low[-1]
      low = float(low[:-1])
  else:
      units = 'u'
      low = float(low)

  if up and not up[-1].isdigit():
      units = up[-1]
      up = float(up[:-1])
  else:
      units = 'u'
      up = float(up)

  return low, up, units

from google.colab.patches import cv2_imshow
import logging

logging.getLogger("PaddleOCR").setLevel(logging.ERROR)

for img_path in img_paths:
    result = ocr_model.ocr(img_path)
    results[img_path] = result

def num_there(s):
    return any(i.isdigit() for i in s)

def only_num(s):
    return s.isnumeric()

def contains_hyphen(text):
    """
    Check if the given text contains the character '-'.

    Args:
        text (str): The text to check.

    Returns:
        bool: True if the text contains '-', False otherwise.
    """
    return '-' in text

# def extract_numbers(test_string):
#   translation_table = str.maketrans('', '', 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~')
#   numeric_string = test_string.translate(translation_table)
#   words = numeric_string.split()
#   numbers = [int(i) for i in words]
#   return numbers

def extract_numbers(test_string):
    numeric_string = ''.join(char for char in test_string if char.isdigit() or char == ',')
    words = numeric_string.split(',')
    numbers = [int(i) for i in words]
    return numbers

# Code to obtain OCR results on the map image by splitting into 2 sub-images
# The 2 sub-images will contain only the Title and only the legend/colour bar area.
# Thus, we perform OCR on the 2 sub-images separately and store the results.

from google.colab.patches import cv2_imshow
import numpy as np
from PIL import Image
from numpy import asarray

# title_bounding_box = [159, 17, 272, 29]
# legend_bounding_box = [249, 471, 325, 25]

complete_data = []

for ele in data:
  file_name = ele[0]
  print(file_name)
  map_type = ele[1]
  title_bounding_box = ele[2]
  legend_bounding_box = ele[3]

  values = extract_numbers(title_bounding_box)

  imgPath = "/content/drive/MyDrive/map_detect/annotation/final_test_set/2018/"+file_name
  image = cv2.imread(imgPath)

  y, x, h, w = values

  cropped_img = image[y:y+h, x:x+w]
  cv2_imshow(cropped_img)
  numpydata = asarray(cropped_img)

  result = ocr_model.ocr(numpydata, cls=False)
  map_title = result[0][0][1][0]

  print(map_title)
  # results[imgPath] = result

  numerical_info = []
  values = extract_numbers(legend_bounding_box)
  y, x, h, w = values

  cropped_img = image[y:y+h, x:x+w]
  cv2_imshow(cropped_img)
  numpydata = asarray(cropped_img)
  image = cropped_img

  result = ocr_model.ocr(numpydata, cls=False)

  for line in result:
    for word in line:
      text = word[1][0]
      print(text)
      x, y, w, h = word[0][0][0], word[0][0][1], abs(word[0][0][0]-word[0][1][0]), abs(word[0][1][1]-word[0][2][1])

      x1 = int(x)
      y1 = int(y+h//2)
      x2 = int(x)
      y2 = int(y+h//2-1)

      while all(image[y1, x1]==image[y2, x2]):
        x2-=1
      x3 = x2
      while all(image[y1, x1]==image[y2, x3]):
        x3-=1

      x2 = (x2+x3)//2
      color = image[y2,x2]
      print(color)
      blue, green, red = color
      numerical_info += [text] + [red, green, blue]

  i=0
  value_id = 0
  while i<len(numerical_info):
    value_id += 1

    if numerical_info[i]!="N/A" and numerical_info[i]!="-":
      values = numerical_info[i].split("-")

      if len(values)>1:
        lower_bound = values[0]
        upper_bound = values[1]
      else:
        lower_bound = values[0]
        upper_bound = values[0]

      converted_lower_bound, converted_upper_bound, units = convert_to_doubles(lower_bound, upper_bound)
      info = [file_name, map_type, map_title, numerical_info[i+1], numerical_info[i+2], numerical_info[i+3], (converted_lower_bound+converted_upper_bound)/2, units]

    else:
      values = "N/A"
      info = [file_name, map_type, map_title, numerical_info[i+1], numerical_info[i+2], numerical_info[i+3], values, ""]

    map_name = img_path.split("/")[-1].split(".")[0]
    info = [map_name] + info
    complete_data += [info]
    i+=4

print(complete_data)

with open('/content/drive/MyDrive/map_detect/annotation/final_result/2018/output.txt', 'w') as f:
    for item in complete_data:
        f.write(str(item) + '\n')

output_df = pd.DataFrame(complete_data)
df = output_df[output_df[7] != 'N/A']

df.to_csv('/content/drive/MyDrive/map_detect/annotation/final_result/2018/OCR_output.csv',index = False)

results

