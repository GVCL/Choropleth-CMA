# -*- coding: utf-8 -*-
"""ResNet50 for Image Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lw8VE_sevNskqco9QWhHMiHWFbaSSmWp
"""

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import shutil
from tensorflow.keras.models import save_model
import numpy as np
from keras.models import load_model
from glob import glob
import matplotlib.pyplot as plt
import os
import cv2

from google.colab import drive
drive.mount('/content/drive')

IMAGE_SIZE = [224,224]

train_path = '/content/drive/MyDrive/legend_classification/train'
valid_path = '/content/drive/MyDrive/legend_classification/val'

resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)
for layer in resnet.layers:
  layer.trainable = False

folders = glob('/content/drive/MyDrive/legend_classification/train/*')
len(folders)

x = Flatten()(resnet.output)
x = Dense(1000, activation='relu')(x)
prediction = Dense(len(folders), activation='softmax')(x)
model = Model(inputs=resnet.input, outputs=prediction)
model.summary()

from keras import optimizers

model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate = 0.0001), metrics=['accuracy'])
train_datagen = ImageDataGenerator(rescale=1./225, width_shift_range=0.1, height_shift_range=0.1)
test_datagen = ImageDataGenerator(rescale=1./225)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/legend_classification/train', target_size=(224, 224), batch_size=1, class_mode='categorical')
test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/legend_classification/val', target_size=(224, 224), batch_size=1, class_mode='categorical')

cla = test_set.classes
print(cla)

r = model.fit(training_set, validation_batch_size=test_set, epochs=20, steps_per_epoch=len(training_set), validation_steps=len(test_set))

save_model(model, '/content/drive/MyDrive/legend_classification/resnet50.h5')

path = '/content/drive/MyDrive/legend_classification/test/map_17.png'

from keras.preprocessing import image
from keras.utils import load_img
img = load_img(path, target_size=(224,224))
img = np.asarray(img)
plt.imshow(img)
img = np.expand_dims(img, axis=0)
output = model.predict(img)
print(output)

output

# predictions = np.array([[1, 0], [0, 1]])

# predicted_labels = np.argmax(predictions, axis=1)
# print(predicted_labels)

# images_directory = '/content/drive/MyDrive/legend_classification/test/'

# for filename in os.listdir(images_directory):
#     if filename.endswith('.png'):
#         path = os.path.join(images_directory, filename)

#         img = load_img(path, target_size=(224, 224))
#         img = np.asarray(img) / 255
#         img = np.expand_dims(img, axis=0)

#         output = model.predict(img)
#         print(output)

#         if output[0][0] > 0.5:
#             save_path = os.path.join('/content/drive/MyDrive/legend_classification/results/choropleth/', filename)
#         else:
#             save_path = os.path.join('/content/drive/MyDrive/pdf_image_classifier/results/isocline/', filename)

#         cv2.imwrite(save_path, cv2.imread(path))

import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import load_img
import csv

csv_file = '/content/drive/MyDrive/legend_classification/resnet/2018/classification_results.csv'
with open(csv_file, mode='w') as file:
    writer = csv.writer(file)
    writer.writerow(['file name', 'Type'])

# images_directory = '/content/drive/MyDrive/legend_classification/final_test/2018'

# for filename in os.listdir(images_directory):
#     if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):
#         path = os.path.join(images_directory, filename)

#         img = load_img(path, target_size=(224, 224))
#         img = np.asarray(img) / 255
#         img = np.expand_dims(img, axis=0)

#         output = model.predict(img)
#         print(output)

#         if output[0][0] > 0.5:
#             file_type = 'continuous'
#             save_path = os.path.join('/content/drive/MyDrive/legend_classification/resnet/2018/continuous', filename)
#         else:
#             file_type = 'discrete'
#             save_path = os.path.join('/content/drive/MyDrive/legend_classification/resnet/2018/discrete', filename)

#         with open(csv_file, mode='a') as file:
#             writer = csv.writer(file)
#             writer.writerow([filename, file_type])

#         cv2.imwrite(save_path, cv2.imread(path))
images_directory = '/content/drive/MyDrive/legend_classification/final_test/2017'

# List to store model predictions and ground truth labels
predictions = []
ground_truth = []

for filename in os.listdir(images_directory):
    if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):
        path = os.path.join(images_directory, filename)

        img = load_img(path, target_size=(224, 224))
        img = np.asarray(img) / 255
        img = np.expand_dims(img, axis=0)

        # Predict
        output = model.predict(img)
        predictions.append(output[0][0])

        # Determine file type
        file_type = 'discrete' if output[0][0] > 0.5 else 'continuous'

        # Determine ground truth label (assuming you have a ground truth label)
        # Replace 'ground_truth_label' with your actual ground truth label
        ground_truth_label = ...  # Get the ground truth label for the current image
        ground_truth.append(ground_truth_label)

        # Save the prediction and file type in the CSV file
        with open(csv_file, mode='a') as file:
            writer = csv.writer(file)
            writer.writerow([filename, file_type, ground_truth_label])

# Calculate accuracy
correct_predictions = sum(1 for pred, gt in zip(predictions, ground_truth) if (pred > 0.5) == gt)
total_images = len(ground_truth)
accuracy = correct_predictions / total_images * 100

print(f'Test accuracy: {accuracy:.2f}%')

loss, accuracy = model.evaluate(images_directory)
print(f'Test accuracy: {accuracy*100:.2f}%')

import pandas as pd

df1 = pd.read_csv("/content/drive/MyDrive/legend_classification/resnet/2017/final_annotation_output.csv")
df2 = pd.read_csv("/content/drive/MyDrive/legend_classification/resnet/2017/classification_results.csv")

result = pd.merge(df1, df2, on='file name')

result.to_csv("/content/drive/MyDrive/legend_classification/final_results/2019/final.csv", index=False)